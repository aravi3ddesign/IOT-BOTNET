{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"background-color:lightpink;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">CLASSIFICATION WITH LOGISTIC REGRESSION</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in Spark\n",
    "\n",
    " The various steps involved in developing a classification model in pySpark are as follows:\n",
    "\n",
    "1) Initialize a Spark session\n",
    "\n",
    "2) Download and read the the dataset\n",
    "\n",
    "3) Developing initial understanding about the data\n",
    "\n",
    "4) Handling missing values\n",
    "\n",
    "5) Scalerizing the features\n",
    "\n",
    "6) Train test split\n",
    "\n",
    "7) Imbalance handling\n",
    "\n",
    "8) Feature selection\n",
    "\n",
    "9) Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-0DFIU6N:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>diabeties</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1c5edacfa90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder. \\\n",
    "appName(\"Major Project\").\\\n",
    "master(\"local[1]\").\\\n",
    "config(\"spark.memory.offHeap.enabled\",\"true\"). \\\n",
    "config(\"spark.memory.offHeap.size\",\"10g\").getOrCreate()\n",
    "\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data =spark.read.csv(r\"C:/Users/abhi/Desktop/project feb2023/major project code/small dataset/train2.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ask is to buid a machine learning model to accurately predict whether or not the patients in the dataset have diabetes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, bidirectional_duration_ms: string, bidirectional_packets: string, bidirectional_bytes: string, src2dst_first_seen_ms: string, src2dst_last_seen_ms: string, src2dst_packets: string, src2dst_bytes: string, dst2src_first_seen_ms: string, dst2src_last_seen_ms: string, dst2src_packets: string, dst2src_bytes: string, dst2src_duration_ms: string, src2dst_duration_ms: string, Target: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+\n",
      "|features                                                                    |\n",
      "+----------------------------------------------------------------------------+\n",
      "|(13,[1,2,3,4,5,6],[1.0,100.0,1.537542439378E12,1.537542439378E12,1.0,100.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,100.0,1.537542439402E12,1.537542439402E12,1.0,100.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,100.0,1.537542439415E12,1.537542439415E12,1.0,100.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,100.0,1.537542443387E12,1.537542443387E12,1.0,100.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,100.0,1.537542443391E12,1.537542443391E12,1.0,100.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,100.0,1.537542455693E12,1.537542455693E12,1.0,100.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532103708659E12,1.532103708659E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532103730254E12,1.532103730254E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532106434466E12,1.532106434466E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532106807748E12,1.532106807748E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532106876197E12,1.532106876197E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532107332704E12,1.532107332704E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532107638216E12,1.532107638216E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532110925529E12,1.532110925529E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532112110052E12,1.532112110052E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532112489559E12,1.532112489559E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.532112500898E12,1.532112500898E12,1.0,110.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,110.0,1.53211623517E12,1.53211623517E12,1.0,110.0])  |\n",
      "|(13,[1,2,3,4,5,6],[1.0,111.0,1.537524688198E12,1.537524688198E12,1.0,111.0])|\n",
      "|(13,[1,2,3,4,5,6],[1.0,132.0,1.536926501032E12,1.536926501032E12,1.0,132.0])|\n",
      "+----------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cols=raw_data.columns\n",
    "cols.remove(\"Target\")\n",
    "# Let us import the vector assembler\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "# Now let us use the transform method to transform our dataset\n",
    "raw_data=assembler.transform(raw_data)\n",
    "raw_data.select(\"features\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Sclarizer \n",
    "\n",
    "So we have created a feature vector. Now let us use StandardScaler to scalerize the newly created \"feature\" column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     Scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|(13,[1,2,3,4,5,6]...|(13,[1,2,3,4,5,6]...|\n",
      "|(13,[1,2,3,4,5,6]...|(13,[1,2,3,4,5,6]...|\n",
      "|(13,[1,2,3,4,5,6]...|(13,[1,2,3,4,5,6]...|\n",
      "|(13,[1,2,3,4,5,6]...|(13,[1,2,3,4,5,6]...|\n",
      "|(13,[1,2,3,4,5,6]...|(13,[1,2,3,4,5,6]...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "standardscaler=StandardScaler().setInputCol(\"features\").setOutputCol(\"Scaled_features\")\n",
    "raw_data=standardscaler.fit(raw_data).transform(raw_data)\n",
    "raw_data.select(\"features\",\"Scaled_features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Train, test split\n",
    "\n",
    "Now that the preprocessing of the data is complete. Let us split the dataset in training and testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "<a id=\"2\"></a>\n",
    "# <p style=\"background-color:lightpink;font-family:newtimeroman;color:#FFF9ED;font-size:150%;text-align:center;border-radius:10px 10px;\">CLASSIFICATION WITH LOGISTIC REGRESSION</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = raw_data.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether their is imbalance in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of ones are 5310104\n",
      "Percentage of ones are 99.99167693868013\n"
     ]
    }
   ],
   "source": [
    "dataset_size=float(train.select(\"Target\").count())\n",
    "numPositives=train.select(\"Target\").where('Target == 1').count()\n",
    "per_ones=(float(numPositives)/float(dataset_size))*100\n",
    "numNegatives=float(dataset_size-numPositives)\n",
    "print('The number of ones are {}'.format(numPositives))\n",
    "print('Percentage of ones are {}'.format(per_ones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BalancingRatio = 8.323061319871818e-05\n"
     ]
    }
   ],
   "source": [
    "BalancingRatio= numNegatives/dataset_size\n",
    "print('BalancingRatio = {}'.format(BalancingRatio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        classWeights|\n",
      "+--------------------+\n",
      "|8.323061319871818E-5|\n",
      "|8.323061319871818E-5|\n",
      "|  0.9999167693868013|\n",
      "|  0.9999167693868013|\n",
      "|  0.9999167693868013|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql.functions import *\n",
    "train=train.withColumn(\"classWeights\",when(train.Target == 0,BalancingRatio).otherwise(1-BalancingRatio))\n",
    "train.select(\"classWeights\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "We use the ChiSqSelector provided by Spark ML for selecting significant features. Please refer my previous blog for more details about working of the ChiSqSelector.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a classification model using Logistic Regression (LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "import time\n",
    "lr = LogisticRegression(labelCol=\"Target\", featuresCol='Scaled_features',weightCol=\"classWeights\",maxIter=10)\n",
    "model=lr.fit(train)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 0.12219858169555664\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "predict_train=model.transform(train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"total time\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time 0.08529520034790039\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "predict_test=model.transform(test)\n",
    "end = time.time()\n",
    "print(\"total time\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|Target|prediction|\n",
      "+------+----------+\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "|     1|       1.0|\n",
      "+------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.select(\"Target\",\"prediction\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bidirectional_duration_ms',\n",
       " 'bidirectional_packets',\n",
       " 'bidirectional_bytes',\n",
       " 'src2dst_first_seen_ms',\n",
       " 'src2dst_last_seen_ms',\n",
       " 'src2dst_packets',\n",
       " 'src2dst_bytes',\n",
       " 'dst2src_first_seen_ms',\n",
       " 'dst2src_last_seen_ms',\n",
       " 'dst2src_packets',\n",
       " 'dst2src_bytes',\n",
       " 'dst2src_duration_ms',\n",
       " 'src2dst_duration_ms',\n",
       " 'Target',\n",
       " 'features',\n",
       " 'Scaled_features',\n",
       " 'rawPrediction',\n",
       " 'probability',\n",
       " 'prediction']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paramGrid = ParamGridBuilder()\\\n",
    "#     .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
    "#     .addGrid(lr.fitIntercept, [False, True])\\\n",
    "#     .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n",
    "#     .build()\n",
    "\n",
    "# https://spark.apache.org/docs/2.1.0/ml-tuning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model\n",
    "\n",
    "Now let us evaluate the model using BinaryClassificationEvaluator class in Spark ML. BinaryClassificationEvaluator by default uses areaUnderROC as the performance metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The BinaryClassificationEvaluator uses areaUnderROC as the default metric. As o fnow we will continue with the same\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "evaluator=BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\",labelCol=\"Target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+----------+--------------------+\n",
      "|Target|       rawPrediction|prediction|         probability|\n",
      "+------+--------------------+----------+--------------------+\n",
      "|     1|[-18.845521373899...|       1.0|[6.53873980482537...|\n",
      "|     1|[-18.845521373566...|       1.0|[6.53873980700126...|\n",
      "|     1|[-18.845521373552...|       1.0|[6.53873980709190...|\n",
      "|     1|[-18.845521359562...|       1.0|[6.53873989857046...|\n",
      "|     1|[-18.845521359493...|       1.0|[6.53873989902375...|\n",
      "+------+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_test.select(\"Target\",\"rawPrediction\",\"prediction\",\"probability\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under ROC for train set is 0.9605533880332757\n",
      "The area under ROC for test set is 0.970945446623839\n"
     ]
    }
   ],
   "source": [
    "print(\"The area under ROC for train set is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters\n",
    "\n",
    "To this point we have developed a classification model using logistic regression. However, the working of logistic regression depends upon the on a number of parameters. As of now we have worked with only the default parameters. Now, let s try to tune the hyperparameters and see whether it make any difference.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you are unsure which parameters to tune pls use \"print(lr.explainParams())\" to get the list of parameters available for tuning  \n",
    "#print(lr.explainParams())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of tunable parameters in LR\n",
    "\n",
    "1) aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
    "\n",
    "2) elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
    "\n",
    "3) family: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\n",
    "\n",
    "4) featuresCol: features column name. (default: features, current: Aspect)\n",
    "\n",
    "5) fitIntercept: whether to fit an intercept term. (default: True)\n",
    "\n",
    "6) labelCol: label column name. (default: label, current: Outcome)\n",
    "\n",
    "7) maxIter: max number of iterations (>= 0). (default: 100, current: 10)\n",
    "\n",
    "8) predictionCol: prediction column name. (default: prediction)\n",
    "\n",
    "9) probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
    "\n",
    "10) rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
    "\n",
    "11) regParam: regularization parameter (>= 0). (default: 0.0)\n",
    "\n",
    "12) standardization: whether to standardize the training features before fitting the model. (default: True)\n",
    "\n",
    "13) threshold: Threshold in binary classification prediction, in range [0, 1].\n",
    "\n",
    "14) If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5)\n",
    "\n",
    "15) thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
    "\n",
    "16) tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
    "\n",
    "17) weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (current: classWeights)\n",
    "\n",
    "\n",
    "Now let us tune some of these parameters and observe their effect on the performance of the algorithm.\n",
    "\n",
    "For the purpose of hyperparameter tuning we will consider the following parameters:\n",
    "\n",
    "1) aggregationDepth [2, 5, 10]\n",
    "\n",
    "2) elasticNetParam [0.0, 0.5, 1.0]\n",
    "\n",
    "3) fitIntercept [True / False]\n",
    "\n",
    "4) maxIter [10, 100, 1000]\n",
    "\n",
    "5) regParam [0.01, 0.5, 2.0]\n",
    "\n",
    "frist off all let us define a parameter grid as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.aggregationDepth,[2,5,10])\\\n",
    "    .addGrid(lr.elasticNetParam,[0.0, 0.5, 1.0])\\\n",
    "    .addGrid(lr.fitIntercept,[False, True])\\\n",
    "    .addGrid(lr.maxIter,[10, 100, 1000])\\\n",
    "    .addGrid(lr.regParam,[0.01, 0.5, 2.0]) \\\n",
    "    .build()\n",
    "\n",
    "# https://spark.apache.org/docs/2.1.0/ml-tuning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n",
    "\n",
    "# Run cross validations\n",
    "cvModel = cv.fit(train)\n",
    "# this will likely take a fair amount of time because of the amount of models that we're creating and testing\n",
    "predict_train=cvModel.transform(train)\n",
    "predict_test=cvModel.transform(test)\n",
    "print(\"The area under ROC for train set after CV  is {}\".format(evaluator.evaluate(predict_train)))\n",
    "print(\"The area under ROC for test set after CV  is {}\".format(evaluator.evaluate(predict_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters and K-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem we have not seen any significant improvement in the performance metric after tuning the hyperparameters. Looks like, the default parameters have worked well for this problem. However, hyperparameter tuning is an important aspect while solving problems with ML and must not be ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work:\n",
    "\n",
    "Few important things still remain, which I have not covered in this blog:\n",
    "    \n",
    "1) Outlier detection\n",
    "\n",
    "2) Imbalance handling \n",
    "\n",
    "The class weighing thechnique which we have used in this work is, currently, suitable only for logisticregression. However, in the case of other algorithms Random Forest, Naive Bayes, Support Vector Machine we may need to use techniques such as Synthetic Minority Oversampling Technique (SMOTE)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful links\n",
    "\n",
    "https://spark.apache.org/docs/2.1.0/ml-tuning.html\n",
    "\n",
    "https://spark.apache.org/docs/2.2.0/mllib-evaluation-metrics.html \n",
    "\n",
    "https://docs.databricks.com/spark/latest/mllib/binary-classification-mllib-pipelines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=raw_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
